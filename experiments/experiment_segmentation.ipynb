{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Segmentation using Wikipedia Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.twitter_api import TwitterAPI\n",
    "from utils.cleaner import TweetCleaner\n",
    "from utils.segmenter import SEDTWikSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SEDTWik Segmenter\n",
      "SEDTWik Segmenter Ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_api = TwitterAPI()\n",
    "tweet_cleaner = TweetCleaner(True, True)\n",
    "tweet_segmenter = SEDTWikSegmenter(wiki_titles_file='data/enwiki-titles-unstemmed-no-stopwords-all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting response from Twitter api...\n"
     ]
    }
   ],
   "source": [
    "tweets = twitter_api.get_tweets('(Ukraine OR Russia) -is:retweet', 50, 1)\n",
    "cleaned_tweets = tweet_cleaner.clean_tweets(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segments = []\n",
    "for tweet in cleaned_tweets['data']:\n",
    "    segments.extend(tweet_segmenter.tweet_segmentation(tweet))\n",
    "    \n",
    "print(segments)\n",
    "%store segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Segmentation using NLTK and Stanford NERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "st3 = StanfordNERTagger('./classifiers/english.all.3class.distsim.crf.ser.gz', \n",
    "                       './stanford-ner.jar', \n",
    "                       encoding='utf-8') \n",
    "\n",
    "st4 = StanfordNERTagger('./classifiers/english.conll.4class.distsim.crf.ser.gz', \n",
    "                       './stanford-ner.jar', \n",
    "                       encoding='utf-8') \n",
    "\n",
    "st7 = StanfordNERTagger('./classifiers/english.muc.7class.distsim.crf.ser.gz', \n",
    "                       './stanford-ner.jar', \n",
    "                       encoding='utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for tweet in cleaned_tweets['data']:\n",
    "    # tagged3 = st3.tag(tweet['text'].split())\n",
    "    # tagged4 = st4.tag(tweet['text'].split())\n",
    "    tagged7 = st7.tag(tweet['text'].split())\n",
    "    \n",
    "    print(tagged7)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation using TextBlob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# TODO: experiment with TEXTBLOB noun tagger\n",
    "from textblob import TextBlob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['himars thats', 'wonder weapon tornado', 'pro ukraine gung ho loudmouth ego', 'noise bucket pub whos', 'war movies worships men uniform', 'russian army', 'morale collapse ukraine', 'point ex security adviser', 'nuclear actions japan precedent', 'wan na', 'fact japan ability retaliate', 'full control lyman russian forces pull', 'billions ukraine', 'florida hurricane victims', 'low interest loans', 'putin vows', 'annexation ukraine intel warns', 'support ukraine accession nato', 'entire history observations', 'support initiative referendum', 'results survey sociological group', 'unreasonable inquire locals', 'exit ukrainejoin russia nd time ensure boundaries theyre', 'vote dont', 'wrong side border', 'ukraine map', 'shows power mediagovt thing propaganda', 'yeah obv thats', 'bro guess', 'things iraq', 'invasion russia', 'retook eastern territory', 'control regions', 'ukraine juan peron falklands', 'distrac people tyrannical rule hyper nationalism', 'territorial expansion victim', 'funny lavern russia', 'support traitor', 'ass elbow', 'way todays', 'guardian kremlin unclear parts ukraine', 'retook eastern territory', 'control regions', 'solutions cheer nation recovers', 'inflation wonder people dont', 'debbie downer senate', 'article natowhile nato members european countries', 'forces ukrainethe victory ukraine', 'security world', 'ukraines accession nato', 'news outlets', 'iran ukraine front page', 'iran selective people', 'magnitsky act', 'government officials', 'use speed', 'sanction russias crimes humanity', 'murder abductions torture corruption', 'real world', 'dimensional world pay attention internet making life', 'war russia', 'war china professor disgrace reagan legacy', 'mr mcatee process', 'touch kdka', 'radio news', 'interview james ukraine lmk', 'jewish nazi ukraine talk imagination', 'contrarian points russia', 'chemical weapons', 'ample opportunities', 'penalty use', 'rt russias gazprom', 'gas payments', 'moral compunction', 'large parts russia', 'international community thing', 'biden wh', 'war russia europe', 'natural gas pipelines germany europe', 'blind usa nato intentions', 'vladimir putin', 'men feed', 'tough challenge', 'russia minorities', 'finland sweden', 'yes countries russia', 'ukraine ukraine georgia grozny russia', 'week review sept sept week', 'release tons methane accelerate', 'tactical nuke ukraine putin', 'whole world', 'russia ukraine', 'success weeks words', 'blame rkiye transport russias exports greek', 'money money greece', 'eez demand aegean', 'international maritime law', 'sure biolabs ukraine dont', 'hard empirical evidence cant conspiracies detrimental', 'season hunker winter ukrainian partisan activity', 'escalate winter russian soldiers', 'cold hungry nervous', 'federation council', 'legal nato', 'flush thats', 'useful turkish', 'leaders lot', 'international court hague', 'halls congress meetings ukraine', 'shitload money ukraine stipend florida puerto rico marxists', 'citizens country measure', 'big mistake', 'cold war', 'people ukraine', 'war westerners', 'weather systems', 'war support russia', 'war africans need hands africa proxy wars', 'new photo frames wallpapers', 'lnr immerse', 'chaos forces', 'whole area', 'russian vehicles', 'israel supports ukraines sovereignty territorial integrity russia', 'map israel', 'solidarity ukraine israel hypocricy', 'new oxford dictionary edition', 'russia corner joke', 'belgorod jokes russia', 'border corner']\n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "for tweet in cleaned_tweets['data']:\n",
    "    segments.extend(TextBlob(tweet['text']).noun_phrases)\n",
    "\n",
    "print(segments)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}