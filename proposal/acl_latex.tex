% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\title{Proposal: Knowledge Graphs for Explainable Reinforcement Learning}

\author{Roel Leenders \\
  University of Twente, Enschede, The Netherlands \\
  \texttt{r.leenders@student.utwente.nl}} 
\begin{document}
\maketitle
% --------------------------------------------
% Rel4KC: A Reinforcement Learning Agent for Knowledge Graph Completion and Validation: http://www.cse.msu.edu/~zhaoxi35/DRL4KDD/1.pdf
% Mining Implicit Entity Preference from User-Item Interaction Data for Knowledge Graph Completion via Adversarial Learning: https://arxiv.org/abs/2003.12718
% Learning to Update Knowledge Graphs by Reading News: https://aclanthology.org/D19-1265.pdf
% Building Dynamic Knowledge Graphs from Text-based Games: https://grlearning.github.io/papers/80.pdf
% Knowledge Infused Learning (K-IL): Towards Deep Incorporation of Knowledge in Deep Learning: https://arxiv.org/abs/1912.00512
% Towards mental time travel: a hierarchical memory for reinforcement learning agents: https://arxiv.org/abs/2105.14039#:~:text=Reinforcement%20learning%20agents%20often%20forget,is%20followed%20by%20distractor%20tasks.

% Knowledge graphs as tools for explainable machine learning: A survey: https://www.sciencedirect.com/science/article/pii/S0004370221001788
% Explainable Reinforcement Learning: A Survey: https://arxiv.org/pdf/2005.06247.pdf
% Playing a Strategy Game with Knowledge-Based Reinforcement Learning: https://arxiv.org/pdf/1908.05472.pdf
% Explainable Reinforcement Learning Through a Causal Lens: https://arxiv.org/pdf/1905.10958.pdf
% ENVIRONMENTS: https://agents.inf.ed.ac.uk/blog/multiagent-learning-environments/
% Keywords: knowledge graph completion (KGC),
\section{Introduction}
% ----------------------------------------
% The introduction gives the context of the work and also the motivation for research in this area. Meant 
% is the „external‟ motivation: what is the relevance of this subject.
% ----------------------------------------

% <something about why XAI is important>
% ----------------------------------------
% Why is explainability so crucial? First, there is one obvious psychology-related reason: 
% ‘if the users do not trust a model or a prediction, they will not use it’ 

In recent years the field of AI has seen an increasing need for explainability. As our computational power increased
and 
As models grew larger and more complex, a performance-transparancy trade-off was introduced \cite{}. 
This trade-off descr
% ----------------------------------------
% AI models exhibit one detrimential characteristic: a performance-transpa- rency trade-off. 
% This describes the fact that the more complex a model’s inner workings, the less clear it 
% is how its predictions or decisions were achieved.

% ----------------------------------------
% especially considering Machine Learning (ML) methods like Reinforcement Learning (RL) where 
% the system learns autonomously, the necessity to understand the underlying reasoning for 
% their decisions becomes apparent.
% &
% explaining and justifying the decisions is now more crucial than ever, especially in the 
% domain of RL where an agent learns by itself, without human interaction.

% Explainable Machine Learning has rapidly become an active area of research, with an explosion 
% of contributions focusing on using a variety of techniques (e.g. visual cues, anchors, saliency 
% maps or counterfactuals [2–4]) to elicit the decisions of both scrutable and inscrutable 
% (black box) methods [5,6]

% ----------------------------------------
% <something about that knowledge graphs have been used to explain large language models>

% Explainable AI systems require completeness and accuracy. This means that an important 
% challenge for the field of Knowledge Representation at scale to increase the information 
% coverage and represent more knowledge explicitly across-domains. Additionally, correctness 
% and freshness of the information in large knowledge graph are necessary, requiring not only 
% the investigation of efficient approaches for knowledge graph evolution at scale [100], but 
% also solutions to maintain high-quality cross-domain knowledge graphs without requiring 
% expensive human labour, which can also lead to resources to be discontinued. 

% ----------------------------------------
% <something about why Knowledge base explanation systems (KBX-systems)>

% KBX-systems have been used in the domains of Image recognition, recommender systems, 
% natural language applications and regressive models

% KBX-systems are more understandable as they provide explanations in the form of symbolic, 
% human-readable rules, but need to trade between the structure and succinctness of the 
% generated explanations, which prevents generalisation across tasks;



% ----------------------------------------
% <something about different XAI methods that have been used within reinforcement learning>

% ----------------------------------------
% <something about how KBX-systems haven't really be used in reinforcement learning>
% A somewhat KBX-system that has been used for reinforcement learning is the causal model proposed by Prashan Madumal et al.
% According to the authors however, one weakness of their approach is that the causal model must be given beforehand. Future work 
% includes using epistemic knowledge of the explainee to provide explanations that are more targeted, and extending the model to 
% continuous domains.

\section{Problem Statement}
% ----------------------------------------
% This component describes the problem the paper will focus on. The motivation of its relevance and its 
% relationship with the state of the art in the scientific field should be given, with references to the 
% literature. This leads to a number of clearly formulated research questions (usually 3 to 6). The research  
% questions should be operational: they can be answered by the method you are using. Expected answers 
% can be given.  
% A hierarchy in the research questions (main questions with sub questions) can be suitable. In this case 
% the relationship between the main question and the sub questions should be clear. 
% Preferably the research questions are emphasized in lay-out. 
% An important aspect of this component is that it should make clear what the paper contributes to the 
% topic: what is new, what does the research add to the existing knowledge. 
% ----------------------------------------
% <Motivation of the relevance of the paper>

% ----------------------------------------
% <Relationship with the state of the art>

% <Problem: Currently deep reinforcement learning models are difficult to explain. Knowledge Graphs are an option for better XAI.
% They, however, have not fully been researched for reinforcement learning models>
% <Research Question 1: To what extent, if any, can a knowledge-graph improve the explainability of a deep RL model?>
% <Sub Question 1: How to construct a knowledge graph of a deep RL model?>

\cite{Arnold2013EI}


\section{Proposed Method of Research}
% ----------------------------------------
% This component describes the methodology you are going to use to answer the research questions and 
% motivates why it is suitable. 
% A remark such as „I will perform a literature study to find answers to the questions‟ is too vague. What 
% type of literature, how do you think the literature will lead you to the answers, etc, are all relevant 
% issues. If your methodology involves experiments, you should show how you intend to set up the 
% experiment, how you think the experiment will answer your questions, etc. 
% ----------------------------------------

\section{Planning}
% ----------------------------------------
% Mile-stones in terms of concrete content/tasks/products to be delivered should be given. Elements of 
% the schedule should relate to steps in your methodology. E.g., if you need to find something from the 
% literature before you can set up your experiment, write down when you need to have it. Say when you 
% will start the experiment. Say when you will start collecting data. Say how long you will take for 
% analysis. Say when you expect to have the answers to your questions.  
% NB Tasks such as “week 45: research” are NOT concrete enough. 
% ----------------------------------------
\subsection{References}

\bibliography{anthology,custom}

\appendix

\section{Example Appendix}
\label{sec:appendix}

This is an appendix.

\end{document}
